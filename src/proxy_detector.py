import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

def get_raw_proxies(url="https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/http.txt"):
    try:
        resp = requests.get(url, timeout=10)
        return ["http://" + line.strip() for line in resp.text.splitlines() if line.strip()]
    except Exception as e:
        print("âŒ ä¸‹è½½ä»£ç†å¤±è´¥:", e)
        return []

def is_proxy_working(proxy):
    test_url = "https://httpbin.org/ip"
    try:
        response = requests.get(test_url, proxies={"http": proxy, "https": proxy}, timeout=5)
        if response.status_code == 200:
            print(f"âœ… æœ‰æ•ˆä»£ç†: {proxy}")
            return proxy
    except:
        pass
    print(f"âŒ æ— æ•ˆä»£ç†: {proxy}")
    return None

def get_working_proxies_concurrent(limit=10, max_workers=50):
    print("ğŸš€ æ­£åœ¨ä¸‹è½½å¹¶æµ‹è¯•ä»£ç†...")
    raw_proxies = get_raw_proxies()
    working = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(is_proxy_working, proxy): proxy for proxy in raw_proxies}
        for future in as_completed(futures):
            result = future.result()
            if result:
                working.append(result)
                if len(working) >= limit:
                    break
    return working

# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    good_proxies = get_working_proxies_concurrent(limit=10)
    print("\nâœ… æœ€ç»ˆå¯ç”¨ä»£ç†åˆ—è¡¨ï¼š")
    print(good_proxies)
